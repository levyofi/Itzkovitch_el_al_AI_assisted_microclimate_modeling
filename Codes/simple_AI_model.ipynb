{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO78zMr7Sg7wSdVuG7gZ5f1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The code is similar to the random forest script.\n",
        "Two changes need to be applied:\n",
        "1. Adding the imports shown below\n",
        "2. replace class cell with the updated class below."
      ],
      "metadata": {
        "id": "MSx3Plz9uf3J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AheYlnjHtJzh"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from osgeo import gdal\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neural_network import MLPRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class M2():\n",
        "\n",
        "    def __init__(self, X_path, y_path, name, map_size = 1_024):\n",
        "        '''\n",
        "        Create model class.\n",
        "        At initiation - create dataframe that contain all paths to input maps\n",
        "        '''\n",
        "        self.name = name\n",
        "        self.N = map_size\n",
        "        self.features = ['TGI', 'height', 'shade', 'real_solar', 'skyview']\n",
        "\n",
        "        files_dict = {'IR':[], 'TGI':[], 'height':[], 'shade':[], 'real_solar':[], 'skyview':[]}\n",
        "        temp_list = glob.glob(f'{y_path}/physical_model/*.tif')\n",
        "        temp_list.sort()\n",
        "        files_dict['M1'] = temp_list\n",
        "        flights = [f.split('/')[-1][:-6] for f in temp_list]\n",
        "        files_dict['Flight'] = flights\n",
        "        for name in np.unique(flights):\n",
        "            for feature in self.features:\n",
        "              temp_list = glob.glob(f'{X_path}/{name}/{feature}_*.tif')\n",
        "              temp_list.sort()\n",
        "              files_dict[feature] += temp_list\n",
        "            temp_list = glob.glob(f'{y_path}/IR_fixed/{name}*.npy')\n",
        "            temp_list.sort()\n",
        "            files_dict['IR'] += temp_list\n",
        "\n",
        "        self.files_df = pd.DataFrame(files_dict)\n",
        "\n",
        "    def split_data(self, pixels, train_set_maps):\n",
        "        '''\n",
        "        Create dataframe for random forest model.\n",
        "        For each map within the train set maps, and for each crop at those maps,\n",
        "        the script takes [pixels] random pixels.\n",
        "        '''\n",
        "        self.train_flights = pd.Series(train_set_maps)\n",
        "        self.len_of_random_pix = pixels\n",
        "\n",
        "        masks = {}\n",
        "        dctNN = {'PredM1': [], 'PredErrorM1':[], 'IR': [],\n",
        "               'TGI': [], 'Height': [], 'Shade': [], 'RealSolar': [], 'Skyview': [],\n",
        "               }\n",
        "\n",
        "        for flight in self.train_flights:\n",
        "            subset = self.files_df[self.files_df['Flight'] == flight].reset_index()\n",
        "            for crop in range(len(subset)):\n",
        "                rand = np.random.randint(0,self.N**2, pixels) # list of random indexes from the map\n",
        "                m = np.zeros((self.N,self.N)).flatten()\n",
        "                m[rand] = 1\n",
        "                masks[f'{flight}_{crop}'] = m.reshape((self.N, self.N))\n",
        "\n",
        "                dctNN['TGI'] += list(gdal.Open(subset['TGI'][crop]).ReadAsArray().flatten()[rand])\n",
        "                dctNN['Height'] += list(gdal.Open(subset['height'][crop]).ReadAsArray().flatten()[rand])\n",
        "                dctNN['Shade'] += list(gdal.Open(subset['shade'][crop]).ReadAsArray().flatten()[rand])\n",
        "                dctNN['RealSolar'] += list(gdal.Open(subset['real_solar'][crop]).ReadAsArray().flatten()[rand])\n",
        "                dctNN['Skyview'] += list(gdal.Open(subset['skyview'][crop]).ReadAsArray().flatten()[rand])\n",
        "\n",
        "                pred_m1 = gdal.Open(subset['M1'][crop]).ReadAsArray().flatten()[rand]\n",
        "                dctNN['PredM1'] += list(pred_m1)\n",
        "\n",
        "                ir = np.load(subset['IR'][crop]).flatten()[rand]\n",
        "                dctNN['IR'] += list(ir)\n",
        "\n",
        "                pred_error_m1 = gdal.Open(subset['M1'][crop]).ReadAsArray().flatten()[rand] - \\\n",
        "                    np.load(subset['IR'][crop]).flatten()[rand] - 273.16\n",
        "                dctNN['PredErrorM1'] += list(pred_error_m1 - np.nanmean(pred_error_m1)) # centralized to calculate the residuals\n",
        "\n",
        "        train_df_NN = pd.DataFrame(dctNN)\n",
        "        train_df_NN = train_df_NN.dropna()\n",
        "        train_df_NN = train_df_NN.reset_index()\n",
        "        self.NN_train_df = train_df_NN\n",
        "\n",
        "        self.mask = masks\n",
        "\n",
        "    def trainNN(self, y_var, plot = False):\n",
        "        '''\n",
        "        run basic MLP pipeline on the training data.\n",
        "        '''\n",
        "        assert y_var in ['IR', 'PredErrorM1']\n",
        "\n",
        "        self.y_var_train = y_var\n",
        "\n",
        "        X = self.NN_train_df.drop(['index', 'PredErrorM1' ,'IR'],1)\n",
        "        if y_var == 'IR':\n",
        "          X = self.NN_train_df.drop(['index', 'PredErrorM1' ,'IR', 'PredM1'],1)\n",
        "        y = self.NN_train_df[y_var]\n",
        "\n",
        "        nn_model = MLPRegressor(hidden_layer_sizes=(10, 10), max_iter=100, random_state=42)\n",
        "        nn_model.fit(X, y)\n",
        "        y_pred = nn_model.predict(X)\n",
        "        r2_NN = r2_score(y, y_pred)\n",
        "        self.NNModel = nn_model\n",
        "        self.trainedR2_NN = r2_NN\n",
        "\n",
        "        print(f'r^2:\\tNN = {r2_NN:.3f}')\n",
        "\n",
        "        if plot:\n",
        "            rand = np.random.randint(0, len(y), 1000)\n",
        "            sns.regplot(x = y[rand], y = y_pred[rand])\n",
        "            plt.ylabel('Predicted')\n",
        "            plt.xlabel('Real')\n",
        "            plt.title('NN model')\n",
        "            plt.show()\n",
        "\n",
        "    def test(self, path):\n",
        "        '''\n",
        "        for maps in test set (not in train set), the function create dataframe from\n",
        "        input maps and run the model.\n",
        "        '''\n",
        "        for flight in self.files_df['Flight'].unique():\n",
        "            if flight in list(self.train_flights):\n",
        "                continue\n",
        "            subset = self.files_df[self.files_df['Flight'] == flight].reset_index()\n",
        "            for crop, sub_flight in enumerate(subset['M1']):\n",
        "                name = sub_flight.split('/')[-1][:-4]\n",
        "                tgi = gdal.Open(subset['TGI'][crop]).ReadAsArray().flatten()\n",
        "                height = gdal.Open(subset['height'][crop]).ReadAsArray().flatten()\n",
        "                shade = gdal.Open(subset['shade'][crop]).ReadAsArray().flatten()\n",
        "                real_solar = gdal.Open(subset['real_solar'][crop]).ReadAsArray().flatten()\n",
        "                skyview = gdal.Open(subset['skyview'][crop]).ReadAsArray().flatten()\n",
        "                pred_m1 = gdal.Open(subset['M1'][crop]).ReadAsArray().flatten()\n",
        "\n",
        "                if self.y_var_train == 'PredErrorM1':\n",
        "                    dataNN = pd.DataFrame({'PredM1':pred_m1,\n",
        "                                         'TGI':tgi, 'Height':height,\n",
        "                                         'Shade':shade, 'RealSolar':real_solar, 'Skyview':skyview})\n",
        "                if self.y_var_train == 'IR':\n",
        "                    dataNN = pd.DataFrame({'TGI':tgi, 'Height':height,\n",
        "                                         'Shade':shade, 'RealSolar':real_solar, 'Skyview':skyview})\n",
        "\n",
        "                m2_map = self.NNModel.predict(dataNN).reshape((self.N, self.N))\n",
        "                np.save(f'{path}/{name}_Model_NN.npy', m2_map)"
      ],
      "metadata": {
        "id": "AIOweynVtvj_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}